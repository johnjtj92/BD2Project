{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  #Importing necessary libraries\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "def load_json_lines(filepath):\n",
    "    data = [] #creates an empty list to store the JSON objects\n",
    "    with open(filepath, \"r\") as f:  #Opens the file for reading\n",
    "        for line in f:\n",
    "            try:\n",
    "                data.append(json.loads(line))   #Adds each JSON object to the list\n",
    "            except json.JSONDecodeError:\n",
    "                continue                #Will skip any lines not valid\n",
    "    return pd.json_normalize(data)   #Converts the list into a Pandas dataframe\n",
    "#Loading all the files\n",
    "products = pd.read_csv(\"products[1].csv\")\n",
    "reviews = pd.read_csv(\"reviews[1].csv\")\n",
    "users = pd.read_csv(\"users[1].csv\")\n",
    "jc_products = load_json_lines(\"jcpenney_products[1].json\")\n",
    "jc_reviewers = load_json_lines(\"jcpenney_reviewers[1].json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have loaded the 5 files into the notebook but to keep it clean, I want to review and clean each file one at a time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7982 entries, 0 to 7981\n",
      "Data columns (total 6 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   Uniq_id      7982 non-null   object \n",
      " 1   SKU          7915 non-null   object \n",
      " 2   Name         7982 non-null   object \n",
      " 3   Description  7439 non-null   object \n",
      " 4   Price        5816 non-null   float64\n",
      " 5   Av_Score     7982 non-null   float64\n",
      "dtypes: float64(2), object(4)\n",
      "memory usage: 374.3+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(                            Uniq_id           SKU  \\\n",
       " 0  b6c0b6bea69c722939585baeac73c13d  pp5006380337   \n",
       " 1  93e5272c51d8cce02597e3ce67b7ad0a  pp5006380337   \n",
       " \n",
       "                                           Name  \\\n",
       " 0  Alfred Dunner® Essential Pull On Capri Pant   \n",
       " 1  Alfred Dunner® Essential Pull On Capri Pant   \n",
       " \n",
       "                                          Description  Price  Av_Score  \n",
       " 0  Youll return to our Alfred Dunner pull-on capr...  41.09     2.625  \n",
       " 1  Youll return to our Alfred Dunner pull-on capr...  41.09     3.000  ,\n",
       " None)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products.head(2), products.info()  #To see a preview of the dataframe, to check column names/data types/non-null counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I first notice different non-null counts and 6 columns with each beginning with a capital letter. I can't assume the other files are in the same format so first I want to clean the column names which I intend to do with every file to keep consistancy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "products.columns = (    #Begin to clean the column names\n",
    "    products.columns\n",
    "    .str.lower()       #Put it all into lower case\n",
    "    .str.strip()       #Remove spaces\n",
    "    .str.replace(\" \", \"_\")  #To use underscores instead\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "uniq_id           0\n",
       "sku              67\n",
       "name              0\n",
       "description     543\n",
       "price          2166\n",
       "av_score          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products.isna().sum() #To see if there is any missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Id/name/score all have 7982 non-null count, so I aim to make description/price/sku the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "products[\"description\"] = products[\"description\"].fillna(\"No description available\")\n",
    "#Replacing empty values in description column with \"No description available\"\n",
    "products[\"price\"] = products[\"price\"].fillna(products[\"price\"].median())\n",
    "#Fills any missing prices with a median price to help balance the dataset instead of completely removing those rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "uniq_id        0\n",
       "sku            0\n",
       "name           0\n",
       "description    0\n",
       "price          0\n",
       "av_score       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products[\"sku\"] = products[\"sku\"].fillna(\"unknown\") # Replace missing SKU values with \"unknown\" to keep the row but mark it clearly.\n",
    "products.isna().sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7982 entries, 0 to 7981\n",
      "Data columns (total 6 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   uniq_id      7982 non-null   object \n",
      " 1   sku          7982 non-null   object \n",
      " 2   name         7982 non-null   object \n",
      " 3   description  7982 non-null   object \n",
      " 4   price        7982 non-null   float64\n",
      " 5   av_score     7982 non-null   float64\n",
      "dtypes: float64(2), object(4)\n",
      "memory usage: 374.3+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(                            uniq_id           sku  \\\n",
       " 0  b6c0b6bea69c722939585baeac73c13d  pp5006380337   \n",
       " 1  93e5272c51d8cce02597e3ce67b7ad0a  pp5006380337   \n",
       " \n",
       "                                           name  \\\n",
       " 0  Alfred Dunner® Essential Pull On Capri Pant   \n",
       " 1  Alfred Dunner® Essential Pull On Capri Pant   \n",
       " \n",
       "                                          description  price  av_score  \n",
       " 0  Youll return to our Alfred Dunner pull-on capr...  41.09     2.625  \n",
       " 1  Youll return to our Alfred Dunner pull-on capr...  41.09     3.000  ,\n",
       " None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products.head(2), products.info() #Review the dataset again to see if the changes have been made"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Products file is now clean, on to the reviews.csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 39063 entries, 0 to 39062\n",
      "Data columns (total 4 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   Uniq_id   39063 non-null  object\n",
      " 1   Username  39063 non-null  object\n",
      " 2   Score     39063 non-null  int64 \n",
      " 3   Review    39063 non-null  object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 1.2+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(                            Uniq_id  Username  Score  \\\n",
       " 0  b6c0b6bea69c722939585baeac73c13d  fsdv4141      2   \n",
       " 1  b6c0b6bea69c722939585baeac73c13d  krpz1113      1   \n",
       " \n",
       "                                               Review  \n",
       " 0  You never have to worry about the fit...Alfred...  \n",
       " 1  Good quality fabric. Perfect fit. Washed very ...  ,\n",
       " None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.head(2), reviews.info() #Now looking at the reviews file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To keep column names consistant with every data set, I will be making them all lower case, removing spaces and adding \"_\" instead. \n",
    "I also want to make sure there is a unique number of IDs in both files to make sure they match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews.columns = (  \n",
    "    reviews.columns\n",
    "    .str.lower()\n",
    "    .str.strip()\n",
    "    .str.replace(\" \", \"_\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7982, 7982)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products[\"uniq_id\"].nunique(), reviews[\"uniq_id\"].nunique() #checking for number of unique entries in the uniq_id columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.duplicated().sum() #checking for duplicated values in each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 39063 entries, 0 to 39062\n",
      "Data columns (total 4 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   uniq_id   39063 non-null  object\n",
      " 1   username  39063 non-null  object\n",
      " 2   score     39063 non-null  int64 \n",
      " 3   review    39063 non-null  object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 1.2+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(                            uniq_id  username  score  \\\n",
       " 0  b6c0b6bea69c722939585baeac73c13d  fsdv4141      2   \n",
       " 1  b6c0b6bea69c722939585baeac73c13d  krpz1113      1   \n",
       " \n",
       "                                               review  \n",
       " 0  You never have to worry about the fit...Alfred...  \n",
       " 1  Good quality fabric. Perfect fit. Washed very ...  ,\n",
       " None)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.head(2), reviews.info()  #final check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reviews file looks clean so on to the users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   Username  5000 non-null   object\n",
      " 1   DOB       5000 non-null   object\n",
      " 2   State     5000 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 117.3+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(   Username         DOB          State\n",
       " 0  bkpn1412  31.07.1983         Oregon\n",
       " 1  gqjs4414  27.07.1998  Massachusetts,\n",
       " None)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users.head(2), users.info()  #Looking at users file summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "users.columns = (  #Keeping consistancy in column names\n",
    "    users.columns\n",
    "    .str.lower()\n",
    "    .str.strip()\n",
    "    .str.replace(\" \", \"_\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   1983-07-31\n",
       "1   1998-07-27\n",
       "2   1950-08-08\n",
       "3   1969-08-03\n",
       "4   2001-07-26\n",
       "Name: dob, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users[\"dob\"] = pd.to_datetime(users[\"dob\"], format=\"%d.%m.%Y\", errors=\"coerce\")  \n",
    "#Converts the date of birth from strings to datetime objects for easier analysis\n",
    "users[\"dob\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to make sure there is no repeated State name, with perhaps one starting with a capital letter and the other not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['Oregon', 'Massachusetts', 'Idaho', 'Florida', 'Georgia',\n",
       "        'Montana', 'Pennsylvania', 'Connecticut', 'Arkansas', 'Nebraska',\n",
       "        'California', 'New Hampshire', 'District of Columbia',\n",
       "        'Washington', 'Minnesota', 'New Mexico', 'Virginia', 'Kansas',\n",
       "        'Illinois', 'North Dakota', 'Colorado', 'New York',\n",
       "        'Minor Outlying Islands', 'Northern Mariana Islands',\n",
       "        'West Virginia', 'Texas', 'South Dakota', 'Maryland', 'Maine',\n",
       "        'Ohio', 'Rhode Island', 'Michigan', 'Alaska', 'Iowa', 'Oklahoma',\n",
       "        'Mississippi', 'South Carolina', 'Missouri', 'New Jersey',\n",
       "        'Tennessee', 'North Carolina', 'Guam', 'Wyoming', 'Delaware',\n",
       "        'Vermont', 'Indiana', 'Louisiana', 'Wisconsin', 'Hawaii',\n",
       "        'Puerto Rico', 'Alabama', 'Kentucky', 'Arizona', 'Nevada', 'Utah',\n",
       "        'American Samoa', 'U.S. Virgin Islands'], dtype=object),\n",
       " 57)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users[\"state\"].unique(), users[\"state\"].nunique()  #Making sure there is no duplicate states and to get how many unique states there are "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype         \n",
      "---  ------    --------------  -----         \n",
      " 0   username  5000 non-null   object        \n",
      " 1   dob       5000 non-null   datetime64[ns]\n",
      " 2   state     5000 non-null   object        \n",
      "dtypes: datetime64[ns](1), object(2)\n",
      "memory usage: 117.3+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(   username        dob          state\n",
       " 0  bkpn1412 1983-07-31         Oregon\n",
       " 1  gqjs4414 1998-07-27  Massachusetts,\n",
       " None)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users.head(2), users.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4999, 4993)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users[\"username\"].nunique(), reviews[\"username\"].nunique()  #Compare number of usernames in users and reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I notice there are a different number of unique usernames in the users/reviews files. I believe this just mean 6 usernames just didn't leave any reviews on products so I shouldn't need to alter this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Users.csv looks clean and column names match, on to the next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7982 entries, 0 to 7981\n",
      "Data columns (total 15 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   uniq_id                 7982 non-null   object \n",
      " 1   sku                     7982 non-null   object \n",
      " 2   name_title              7982 non-null   object \n",
      " 3   description             7982 non-null   object \n",
      " 4   list_price              7982 non-null   object \n",
      " 5   sale_price              7982 non-null   object \n",
      " 6   category                7982 non-null   object \n",
      " 7   category_tree           7982 non-null   object \n",
      " 8   average_product_rating  7982 non-null   float64\n",
      " 9   product_url             7982 non-null   object \n",
      " 10  product_image_urls      7982 non-null   object \n",
      " 11  brand                   7982 non-null   object \n",
      " 12  total_number_reviews    7982 non-null   int64  \n",
      " 13  Reviews                 7982 non-null   object \n",
      " 14  Bought With             7982 non-null   object \n",
      "dtypes: float64(1), int64(1), object(13)\n",
      "memory usage: 935.5+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(                            uniq_id           sku  \\\n",
       " 0  b6c0b6bea69c722939585baeac73c13d  pp5006380337   \n",
       " 1  93e5272c51d8cce02597e3ce67b7ad0a  pp5006380337   \n",
       " \n",
       "                                     name_title  \\\n",
       " 0  Alfred Dunner® Essential Pull On Capri Pant   \n",
       " 1  Alfred Dunner® Essential Pull On Capri Pant   \n",
       " \n",
       "                                          description list_price sale_price  \\\n",
       " 0  You'll return to our Alfred Dunner pull-on cap...      41.09      24.16   \n",
       " 1  You'll return to our Alfred Dunner pull-on cap...      41.09      24.16   \n",
       " \n",
       "         category                 category_tree  average_product_rating  \\\n",
       " 0  alfred dunner  jcpenney|women|alfred dunner                   2.625   \n",
       " 1  alfred dunner  jcpenney|women|alfred dunner                   3.000   \n",
       " \n",
       "                                          product_url  \\\n",
       " 0  http://www.jcpenney.com/alfred-dunner-essentia...   \n",
       " 1  http://www.jcpenney.com/alfred-dunner-essentia...   \n",
       " \n",
       "                                   product_image_urls          brand  \\\n",
       " 0  http://s7d9.scene7.com/is/image/JCPenney/DP122...  Alfred Dunner   \n",
       " 1  http://s7d9.scene7.com/is/image/JCPenney/DP122...  Alfred Dunner   \n",
       " \n",
       "    total_number_reviews                                            Reviews  \\\n",
       " 0                     8  [{'User': 'fsdv4141', 'Review': 'You never hav...   \n",
       " 1                     8  [{'User': 'tpcu2211', 'Review': 'You never hav...   \n",
       " \n",
       "                                          Bought With  \n",
       " 0  [898e42fe937a33e8ce5e900ca7a4d924, 8c02c262567...  \n",
       " 1  [bc9ab3406dcaa84a123b9da862e6367d, 18eb69e8fc2...  ,\n",
       " None)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jc_products.head(2), jc_products.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "jc_products.columns = (  #Noticed some capital letters again in column names so doing this for consistancy with names\n",
    "    jc_products.columns\n",
    "    .str.lower()\n",
    "    .str.strip()\n",
    "    .str.replace(\" \", \"_\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I noticed several columns in the jc_products dataset had identical values but were named differently so here I am changing their names to match the other data sets for an easier merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "jc_products = jc_products.rename(columns={  #Renaming column names to shorter, simpler versions which match other files\n",
    "    \"name_title\": \"name\",\n",
    "    \"list_price\": \"price\",\n",
    "    \"average_product_rating\": \"av_score\",\n",
    "    \"reviews\": \"review\"\n",
    "})   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "uniq_id                 0\n",
       "sku                     0\n",
       "name                    0\n",
       "description             0\n",
       "price                   0\n",
       "sale_price              0\n",
       "category                0\n",
       "category_tree           0\n",
       "av_score                0\n",
       "product_url             0\n",
       "product_image_urls      0\n",
       "brand                   0\n",
       "total_number_reviews    0\n",
       "review                  0\n",
       "bought_with             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jc_products.isna().sum() #Noticed all non-null counts correct but double checking for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [{'User': 'fsdv4141', 'Review': 'You never hav...\n",
       "1    [{'User': 'tpcu2211', 'Review': 'You never hav...\n",
       "Name: review, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jc_products[\"review\"].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I noticed in jc_products that the review column also maintains the User name and it appears, also repeated reviews.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 39063 entries, 0 to 7981\n",
      "Data columns (total 17 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   uniq_id               39063 non-null  object \n",
      " 1   sku                   39063 non-null  object \n",
      " 2   name                  39063 non-null  object \n",
      " 3   description           39063 non-null  object \n",
      " 4   price                 39063 non-null  object \n",
      " 5   sale_price            39063 non-null  object \n",
      " 6   category              39063 non-null  object \n",
      " 7   category_tree         39063 non-null  object \n",
      " 8   av_score              39063 non-null  float64\n",
      " 9   product_url           39063 non-null  object \n",
      " 10  product_image_urls    39063 non-null  object \n",
      " 11  brand                 39063 non-null  object \n",
      " 12  total_number_reviews  39063 non-null  int64  \n",
      " 13  bought_with           39063 non-null  object \n",
      " 14  User                  39063 non-null  object \n",
      " 15  Review                39063 non-null  object \n",
      " 16  Score                 39063 non-null  int64  \n",
      "dtypes: float64(1), int64(2), object(14)\n",
      "memory usage: 5.4+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(                            uniq_id           sku  \\\n",
       " 0  b6c0b6bea69c722939585baeac73c13d  pp5006380337   \n",
       " 0  b6c0b6bea69c722939585baeac73c13d  pp5006380337   \n",
       " \n",
       "                                           name  \\\n",
       " 0  Alfred Dunner® Essential Pull On Capri Pant   \n",
       " 0  Alfred Dunner® Essential Pull On Capri Pant   \n",
       " \n",
       "                                          description  price sale_price  \\\n",
       " 0  You'll return to our Alfred Dunner pull-on cap...  41.09      24.16   \n",
       " 0  You'll return to our Alfred Dunner pull-on cap...  41.09      24.16   \n",
       " \n",
       "         category                 category_tree  av_score  \\\n",
       " 0  alfred dunner  jcpenney|women|alfred dunner     2.625   \n",
       " 0  alfred dunner  jcpenney|women|alfred dunner     2.625   \n",
       " \n",
       "                                          product_url  \\\n",
       " 0  http://www.jcpenney.com/alfred-dunner-essentia...   \n",
       " 0  http://www.jcpenney.com/alfred-dunner-essentia...   \n",
       " \n",
       "                                   product_image_urls          brand  \\\n",
       " 0  http://s7d9.scene7.com/is/image/JCPenney/DP122...  Alfred Dunner   \n",
       " 0  http://s7d9.scene7.com/is/image/JCPenney/DP122...  Alfred Dunner   \n",
       " \n",
       "    total_number_reviews                                        bought_with  \\\n",
       " 0                     8  [898e42fe937a33e8ce5e900ca7a4d924, 8c02c262567...   \n",
       " 0                     8  [898e42fe937a33e8ce5e900ca7a4d924, 8c02c262567...   \n",
       " \n",
       "        User                                             Review  Score  \n",
       " 0  fsdv4141  You never have to worry about the fit...Alfred...      2  \n",
       " 0  krpz1113  Good quality fabric. Perfect fit. Washed very ...      4  ,\n",
       " None)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jc_products = jc_products.explode(\"review\")  #Putting the list of reviews into separate rows\n",
    "\n",
    "review_details = jc_products[\"review\"].apply(pd.Series) #converting the dictionaries to separate columns\n",
    "\n",
    "jc_products = pd.concat([jc_products.drop(columns=[\"review\"]), review_details], axis=1)  #Removing old review column and replacing with the new ones\n",
    "\n",
    "jc_products.head(2), jc_products.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I now notice the review column actually maintained the username, review and score, so I want to make sure these new column names are all consistant with the others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uniq_id</th>\n",
       "      <th>sku</th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>price</th>\n",
       "      <th>sale_price</th>\n",
       "      <th>category</th>\n",
       "      <th>category_tree</th>\n",
       "      <th>av_score</th>\n",
       "      <th>product_url</th>\n",
       "      <th>product_image_urls</th>\n",
       "      <th>brand</th>\n",
       "      <th>total_number_reviews</th>\n",
       "      <th>bought_with</th>\n",
       "      <th>user</th>\n",
       "      <th>review</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b6c0b6bea69c722939585baeac73c13d</td>\n",
       "      <td>pp5006380337</td>\n",
       "      <td>Alfred Dunner® Essential Pull On Capri Pant</td>\n",
       "      <td>You'll return to our Alfred Dunner pull-on cap...</td>\n",
       "      <td>41.09</td>\n",
       "      <td>24.16</td>\n",
       "      <td>alfred dunner</td>\n",
       "      <td>jcpenney|women|alfred dunner</td>\n",
       "      <td>2.625</td>\n",
       "      <td>http://www.jcpenney.com/alfred-dunner-essentia...</td>\n",
       "      <td>http://s7d9.scene7.com/is/image/JCPenney/DP122...</td>\n",
       "      <td>Alfred Dunner</td>\n",
       "      <td>8</td>\n",
       "      <td>[898e42fe937a33e8ce5e900ca7a4d924, 8c02c262567...</td>\n",
       "      <td>fsdv4141</td>\n",
       "      <td>You never have to worry about the fit...Alfred...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b6c0b6bea69c722939585baeac73c13d</td>\n",
       "      <td>pp5006380337</td>\n",
       "      <td>Alfred Dunner® Essential Pull On Capri Pant</td>\n",
       "      <td>You'll return to our Alfred Dunner pull-on cap...</td>\n",
       "      <td>41.09</td>\n",
       "      <td>24.16</td>\n",
       "      <td>alfred dunner</td>\n",
       "      <td>jcpenney|women|alfred dunner</td>\n",
       "      <td>2.625</td>\n",
       "      <td>http://www.jcpenney.com/alfred-dunner-essentia...</td>\n",
       "      <td>http://s7d9.scene7.com/is/image/JCPenney/DP122...</td>\n",
       "      <td>Alfred Dunner</td>\n",
       "      <td>8</td>\n",
       "      <td>[898e42fe937a33e8ce5e900ca7a4d924, 8c02c262567...</td>\n",
       "      <td>krpz1113</td>\n",
       "      <td>Good quality fabric. Perfect fit. Washed very ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            uniq_id           sku  \\\n",
       "0  b6c0b6bea69c722939585baeac73c13d  pp5006380337   \n",
       "0  b6c0b6bea69c722939585baeac73c13d  pp5006380337   \n",
       "\n",
       "                                          name  \\\n",
       "0  Alfred Dunner® Essential Pull On Capri Pant   \n",
       "0  Alfred Dunner® Essential Pull On Capri Pant   \n",
       "\n",
       "                                         description  price sale_price  \\\n",
       "0  You'll return to our Alfred Dunner pull-on cap...  41.09      24.16   \n",
       "0  You'll return to our Alfred Dunner pull-on cap...  41.09      24.16   \n",
       "\n",
       "        category                 category_tree  av_score  \\\n",
       "0  alfred dunner  jcpenney|women|alfred dunner     2.625   \n",
       "0  alfred dunner  jcpenney|women|alfred dunner     2.625   \n",
       "\n",
       "                                         product_url  \\\n",
       "0  http://www.jcpenney.com/alfred-dunner-essentia...   \n",
       "0  http://www.jcpenney.com/alfred-dunner-essentia...   \n",
       "\n",
       "                                  product_image_urls          brand  \\\n",
       "0  http://s7d9.scene7.com/is/image/JCPenney/DP122...  Alfred Dunner   \n",
       "0  http://s7d9.scene7.com/is/image/JCPenney/DP122...  Alfred Dunner   \n",
       "\n",
       "   total_number_reviews                                        bought_with  \\\n",
       "0                     8  [898e42fe937a33e8ce5e900ca7a4d924, 8c02c262567...   \n",
       "0                     8  [898e42fe937a33e8ce5e900ca7a4d924, 8c02c262567...   \n",
       "\n",
       "       user                                             review  score  \n",
       "0  fsdv4141  You never have to worry about the fit...Alfred...      2  \n",
       "0  krpz1113  Good quality fabric. Perfect fit. Washed very ...      4  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jc_products.columns = (   #putting all in lower case for consistancy\n",
    "    jc_products.columns\n",
    "    .str.lower()\n",
    "    .str.strip()\n",
    "    .str.replace(\" \", \"_\")\n",
    ")\n",
    "\n",
    "jc_products.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to make sure there are no duplicates but received an error at first indicating a column contains lists which I did not notice at first but upon looking back on it, I see the \"bought_with\" column contains lists so I am going to create a new dataset temporarily without that column to check for duplicates.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jc_products_no_lists = jc_products.drop(columns=[\"bought_with\"])  #Removes the bought_with column and creates a new dataset\n",
    "\n",
    "jc_products_no_lists.duplicated().sum() #checking for duplicate values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no duplicates so on to JC reviewers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 4 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   Username  5000 non-null   object\n",
      " 1   DOB       5000 non-null   object\n",
      " 2   State     5000 non-null   object\n",
      " 3   Reviewed  5000 non-null   object\n",
      "dtypes: object(4)\n",
      "memory usage: 156.4+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(   Username         DOB          State                            Reviewed\n",
       " 0  bkpn1412  31.07.1983         Oregon  [cea76118f6a9110a893de2b7654319c0]\n",
       " 1  gqjs4414  27.07.1998  Massachusetts  [fa04fe6c0dd5189f54fe600838da43d3],\n",
       " None)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jc_reviewers.head(2),jc_reviewers.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "jc_reviewers.columns = ( \n",
    "    jc_reviewers.columns\n",
    "    .str.lower()\n",
    "    .str.strip()\n",
    "    .str.replace(\" \", \"_\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>dob</th>\n",
       "      <th>state</th>\n",
       "      <th>reviewed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bkpn1412</td>\n",
       "      <td>1983-07-31</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>[cea76118f6a9110a893de2b7654319c0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gqjs4414</td>\n",
       "      <td>1998-07-27</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>[fa04fe6c0dd5189f54fe600838da43d3]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   username        dob          state                            reviewed\n",
       "0  bkpn1412 1983-07-31         Oregon  [cea76118f6a9110a893de2b7654319c0]\n",
       "1  gqjs4414 1998-07-27  Massachusetts  [fa04fe6c0dd5189f54fe600838da43d3]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jc_reviewers[\"dob\"] = pd.to_datetime(jc_reviewers[\"dob\"], format=\"%d.%m.%Y\", errors=\"coerce\")  \n",
    "#Converting to datetime objects again for possible age analysis\n",
    "jc_reviewers.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "username    0\n",
       "dob         0\n",
       "state       0\n",
       "reviewed    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jc_reviewers.isna().sum() #Checking for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jc_reviewers[\"state\"].nunique()  #Making sure the states match up with the reviews file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to merge the datasets now and if i spot anything wrong, I could then restart or hopefully alter the merged dataset. As column names are repeated, I want to make it easier to remove the duplicated columns so I added the suffixes to each one so it is easier to identify which columns to remove."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((279203, 30),\n",
       " Index(['uniq_id', 'username', 'score', 'review', 'sku', 'name', 'description',\n",
       "        'price', 'av_score', 'sku_json', 'name_json', 'description_json',\n",
       "        'price_json', 'sale_price', 'category', 'category_tree',\n",
       "        'av_score_json', 'product_url', 'product_image_urls', 'brand',\n",
       "        'total_number_reviews', 'bought_with', 'user', 'review_json',\n",
       "        'score_json', 'dob', 'state', 'dob_jsonrev', 'state_jsonrev',\n",
       "        'reviewed'],\n",
       "       dtype='object'))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_merged = (   \n",
    "    reviews\n",
    "    .merge(products, on=\"uniq_id\", how=\"left\", suffixes=(\"\", \"_prod\"))  #\n",
    "    .merge(jc_products, on=\"uniq_id\", how=\"left\", suffixes=(\"\", \"_json\"))\n",
    "    .merge(users, on=\"username\", how=\"left\", suffixes=(\"\", \"_user\"))\n",
    "    .merge(jc_reviewers, on=\"username\", how=\"left\", suffixes=(\"\", \"_jsonrev\"))\n",
    ")\n",
    "#Merging the 4 datasets - if a column name is the same, instead of overwriting each other, \n",
    "#the column will get a suffix added at the end for easier removal afterwards\n",
    "final_merged.shape, final_merged.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['uniq_id', 'username', 'score', 'review', 'sku', 'name', 'description',\n",
       "       'price', 'av_score', 'sale_price', 'category', 'category_tree',\n",
       "       'product_url', 'product_image_urls', 'brand', 'total_number_reviews',\n",
       "       'bought_with', 'user', 'dob', 'state', 'reviewed'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_merged = final_merged.drop(columns=[\n",
    "    \"sku_json\",          #Removing all the columns that were duplicates when merged\n",
    "    \"name_json\",\n",
    "    \"description_json\",\n",
    "    \"price_json\",\n",
    "    \"av_score_json\",\n",
    "    \"review_json\",\n",
    "    \"score_json\",\n",
    "    \"dob_jsonrev\",\n",
    "    \"state_jsonrev\"\n",
    "]) \n",
    "\n",
    "final_merged.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uniq_id</th>\n",
       "      <th>username</th>\n",
       "      <th>score</th>\n",
       "      <th>review</th>\n",
       "      <th>sku</th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>price</th>\n",
       "      <th>av_score</th>\n",
       "      <th>sale_price</th>\n",
       "      <th>...</th>\n",
       "      <th>category_tree</th>\n",
       "      <th>product_url</th>\n",
       "      <th>product_image_urls</th>\n",
       "      <th>brand</th>\n",
       "      <th>total_number_reviews</th>\n",
       "      <th>bought_with</th>\n",
       "      <th>user</th>\n",
       "      <th>dob</th>\n",
       "      <th>state</th>\n",
       "      <th>reviewed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b6c0b6bea69c722939585baeac73c13d</td>\n",
       "      <td>fsdv4141</td>\n",
       "      <td>2</td>\n",
       "      <td>You never have to worry about the fit...Alfred...</td>\n",
       "      <td>pp5006380337</td>\n",
       "      <td>Alfred Dunner® Essential Pull On Capri Pant</td>\n",
       "      <td>Youll return to our Alfred Dunner pull-on capr...</td>\n",
       "      <td>41.09</td>\n",
       "      <td>2.625</td>\n",
       "      <td>24.16</td>\n",
       "      <td>...</td>\n",
       "      <td>jcpenney|women|alfred dunner</td>\n",
       "      <td>http://www.jcpenney.com/alfred-dunner-essentia...</td>\n",
       "      <td>http://s7d9.scene7.com/is/image/JCPenney/DP122...</td>\n",
       "      <td>Alfred Dunner</td>\n",
       "      <td>8</td>\n",
       "      <td>[898e42fe937a33e8ce5e900ca7a4d924, 8c02c262567...</td>\n",
       "      <td>fsdv4141</td>\n",
       "      <td>1980-07-31</td>\n",
       "      <td>American Samoa</td>\n",
       "      <td>[0144d2094668b42ae7c674915806f5f3, 7c27ffd820c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b6c0b6bea69c722939585baeac73c13d</td>\n",
       "      <td>fsdv4141</td>\n",
       "      <td>2</td>\n",
       "      <td>You never have to worry about the fit...Alfred...</td>\n",
       "      <td>pp5006380337</td>\n",
       "      <td>Alfred Dunner® Essential Pull On Capri Pant</td>\n",
       "      <td>Youll return to our Alfred Dunner pull-on capr...</td>\n",
       "      <td>41.09</td>\n",
       "      <td>2.625</td>\n",
       "      <td>24.16</td>\n",
       "      <td>...</td>\n",
       "      <td>jcpenney|women|alfred dunner</td>\n",
       "      <td>http://www.jcpenney.com/alfred-dunner-essentia...</td>\n",
       "      <td>http://s7d9.scene7.com/is/image/JCPenney/DP122...</td>\n",
       "      <td>Alfred Dunner</td>\n",
       "      <td>8</td>\n",
       "      <td>[898e42fe937a33e8ce5e900ca7a4d924, 8c02c262567...</td>\n",
       "      <td>krpz1113</td>\n",
       "      <td>1980-07-31</td>\n",
       "      <td>American Samoa</td>\n",
       "      <td>[0144d2094668b42ae7c674915806f5f3, 7c27ffd820c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            uniq_id  username  score  \\\n",
       "0  b6c0b6bea69c722939585baeac73c13d  fsdv4141      2   \n",
       "1  b6c0b6bea69c722939585baeac73c13d  fsdv4141      2   \n",
       "\n",
       "                                              review           sku  \\\n",
       "0  You never have to worry about the fit...Alfred...  pp5006380337   \n",
       "1  You never have to worry about the fit...Alfred...  pp5006380337   \n",
       "\n",
       "                                          name  \\\n",
       "0  Alfred Dunner® Essential Pull On Capri Pant   \n",
       "1  Alfred Dunner® Essential Pull On Capri Pant   \n",
       "\n",
       "                                         description  price  av_score  \\\n",
       "0  Youll return to our Alfred Dunner pull-on capr...  41.09     2.625   \n",
       "1  Youll return to our Alfred Dunner pull-on capr...  41.09     2.625   \n",
       "\n",
       "  sale_price  ...                 category_tree  \\\n",
       "0      24.16  ...  jcpenney|women|alfred dunner   \n",
       "1      24.16  ...  jcpenney|women|alfred dunner   \n",
       "\n",
       "                                         product_url  \\\n",
       "0  http://www.jcpenney.com/alfred-dunner-essentia...   \n",
       "1  http://www.jcpenney.com/alfred-dunner-essentia...   \n",
       "\n",
       "                                  product_image_urls          brand  \\\n",
       "0  http://s7d9.scene7.com/is/image/JCPenney/DP122...  Alfred Dunner   \n",
       "1  http://s7d9.scene7.com/is/image/JCPenney/DP122...  Alfred Dunner   \n",
       "\n",
       "  total_number_reviews                                        bought_with  \\\n",
       "0                    8  [898e42fe937a33e8ce5e900ca7a4d924, 8c02c262567...   \n",
       "1                    8  [898e42fe937a33e8ce5e900ca7a4d924, 8c02c262567...   \n",
       "\n",
       "       user        dob           state  \\\n",
       "0  fsdv4141 1980-07-31  American Samoa   \n",
       "1  krpz1113 1980-07-31  American Samoa   \n",
       "\n",
       "                                            reviewed  \n",
       "0  [0144d2094668b42ae7c674915806f5f3, 7c27ffd820c...  \n",
       "1  [0144d2094668b42ae7c674915806f5f3, 7c27ffd820c...  \n",
       "\n",
       "[2 rows x 21 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_merged.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(240140)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_merged.duplicated(subset=[\"uniq_id\", \"username\", \"score\", \"review\", \"sku\", \"name\", \"description\", \"price\", \"av_score\", \"sale_price\"]).sum()\n",
    "#Checking for duplicated rows using key columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I notice the non-null count is much higher than before. So i want to check for duplicates. Seeing the first 5 entries I notice they are all repeated. I also notice the username/user do not match up but the username is being repeated(as it should be expected with all the the other columns being repeated). I am deciding to drop the user column as it shouldn't be needed alongside the username column which seems to reflect the information accurately, then I will drop the duplicated columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_merged = final_merged.drop(columns=[\"user\"])   #removing the user column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uniq_id</th>\n",
       "      <th>username</th>\n",
       "      <th>score</th>\n",
       "      <th>review</th>\n",
       "      <th>sku</th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>price</th>\n",
       "      <th>av_score</th>\n",
       "      <th>sale_price</th>\n",
       "      <th>category</th>\n",
       "      <th>category_tree</th>\n",
       "      <th>product_url</th>\n",
       "      <th>product_image_urls</th>\n",
       "      <th>brand</th>\n",
       "      <th>total_number_reviews</th>\n",
       "      <th>bought_with</th>\n",
       "      <th>dob</th>\n",
       "      <th>state</th>\n",
       "      <th>reviewed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b6c0b6bea69c722939585baeac73c13d</td>\n",
       "      <td>fsdv4141</td>\n",
       "      <td>2</td>\n",
       "      <td>You never have to worry about the fit...Alfred...</td>\n",
       "      <td>pp5006380337</td>\n",
       "      <td>Alfred Dunner® Essential Pull On Capri Pant</td>\n",
       "      <td>Youll return to our Alfred Dunner pull-on capr...</td>\n",
       "      <td>41.09</td>\n",
       "      <td>2.625</td>\n",
       "      <td>24.16</td>\n",
       "      <td>alfred dunner</td>\n",
       "      <td>jcpenney|women|alfred dunner</td>\n",
       "      <td>http://www.jcpenney.com/alfred-dunner-essentia...</td>\n",
       "      <td>http://s7d9.scene7.com/is/image/JCPenney/DP122...</td>\n",
       "      <td>Alfred Dunner</td>\n",
       "      <td>8</td>\n",
       "      <td>[898e42fe937a33e8ce5e900ca7a4d924, 8c02c262567...</td>\n",
       "      <td>1980-07-31</td>\n",
       "      <td>American Samoa</td>\n",
       "      <td>[0144d2094668b42ae7c674915806f5f3, 7c27ffd820c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>b6c0b6bea69c722939585baeac73c13d</td>\n",
       "      <td>krpz1113</td>\n",
       "      <td>1</td>\n",
       "      <td>Good quality fabric. Perfect fit. Washed very ...</td>\n",
       "      <td>pp5006380337</td>\n",
       "      <td>Alfred Dunner® Essential Pull On Capri Pant</td>\n",
       "      <td>Youll return to our Alfred Dunner pull-on capr...</td>\n",
       "      <td>41.09</td>\n",
       "      <td>2.625</td>\n",
       "      <td>24.16</td>\n",
       "      <td>alfred dunner</td>\n",
       "      <td>jcpenney|women|alfred dunner</td>\n",
       "      <td>http://www.jcpenney.com/alfred-dunner-essentia...</td>\n",
       "      <td>http://s7d9.scene7.com/is/image/JCPenney/DP122...</td>\n",
       "      <td>Alfred Dunner</td>\n",
       "      <td>8</td>\n",
       "      <td>[898e42fe937a33e8ce5e900ca7a4d924, 8c02c262567...</td>\n",
       "      <td>1987-07-30</td>\n",
       "      <td>Virginia</td>\n",
       "      <td>[9ce30016f492e7cc09e4554d4c67230d, b28e5508c1b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            uniq_id  username  score  \\\n",
       "0  b6c0b6bea69c722939585baeac73c13d  fsdv4141      2   \n",
       "8  b6c0b6bea69c722939585baeac73c13d  krpz1113      1   \n",
       "\n",
       "                                              review           sku  \\\n",
       "0  You never have to worry about the fit...Alfred...  pp5006380337   \n",
       "8  Good quality fabric. Perfect fit. Washed very ...  pp5006380337   \n",
       "\n",
       "                                          name  \\\n",
       "0  Alfred Dunner® Essential Pull On Capri Pant   \n",
       "8  Alfred Dunner® Essential Pull On Capri Pant   \n",
       "\n",
       "                                         description  price  av_score  \\\n",
       "0  Youll return to our Alfred Dunner pull-on capr...  41.09     2.625   \n",
       "8  Youll return to our Alfred Dunner pull-on capr...  41.09     2.625   \n",
       "\n",
       "  sale_price       category                 category_tree  \\\n",
       "0      24.16  alfred dunner  jcpenney|women|alfred dunner   \n",
       "8      24.16  alfred dunner  jcpenney|women|alfred dunner   \n",
       "\n",
       "                                         product_url  \\\n",
       "0  http://www.jcpenney.com/alfred-dunner-essentia...   \n",
       "8  http://www.jcpenney.com/alfred-dunner-essentia...   \n",
       "\n",
       "                                  product_image_urls          brand  \\\n",
       "0  http://s7d9.scene7.com/is/image/JCPenney/DP122...  Alfred Dunner   \n",
       "8  http://s7d9.scene7.com/is/image/JCPenney/DP122...  Alfred Dunner   \n",
       "\n",
       "   total_number_reviews                                        bought_with  \\\n",
       "0                     8  [898e42fe937a33e8ce5e900ca7a4d924, 8c02c262567...   \n",
       "8                     8  [898e42fe937a33e8ce5e900ca7a4d924, 8c02c262567...   \n",
       "\n",
       "         dob           state  \\\n",
       "0 1980-07-31  American Samoa   \n",
       "8 1987-07-30        Virginia   \n",
       "\n",
       "                                            reviewed  \n",
       "0  [0144d2094668b42ae7c674915806f5f3, 7c27ffd820c...  \n",
       "8  [9ce30016f492e7cc09e4554d4c67230d, b28e5508c1b...  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_merged = final_merged.drop_duplicates(\n",
    "    subset=[\"uniq_id\", \"username\", \"score\", \"review\", \"sku\", \"name\", \"description\", \"price\", \"av_score\", \"sale_price\"],\n",
    "  )   #Removes all duplicated rows but keeps the first\n",
    "\n",
    "final_merged.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No more duplicates and the dataset looks good so I want to test some analysis/plots and with that information, hopefully it will raise more questions that I could then go on to answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis/Insights/Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading libraries needed for plotting/analysis\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My initial thoughts: First I wanted to see some plots such as what the top 20 categories were, which states reviewed the most(as that could indicate which states buy the most), what the relationship between price/rating is(does rating get higher when price does?), which products were the highest rated? Does the number of reviews a product receives correlate with their rating, so do people only send in reviews for bad products? Perhaps seeing the plots will let me think of other questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "#runs the cell but doesn't show output when converted to pdf - to reduce page count\n",
    "top20_categories = (                                #Creating a dataset for the top 20 ratings by category\n",
    "    final_merged.groupby(\"category\")[\"score\"]\n",
    "    .mean()\n",
    "    .sort_values(ascending=False)   #Top / Highest\n",
    "    .head(10)           #To only show 10\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(8, 5))  #adjusts the size of the plot by width,height\n",
    "sns.barplot(data=top20_categories, x=\"score\", y=\"category\", hue = \"category\")   #Plotting a barplot for score vs category in top20 dataset\n",
    "plt.title(\"Top 10 Categories by Rating\", fontsize=14, weight=\"bold\") #Plots the title at the top of the plot\n",
    "plt.xlabel(\"Rating\") #X-axis title\n",
    "plt.ylabel(\"Product Category\") #Y-axis title\n",
    "plt.show()   #Shows the plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "#can remove capture and run cell to show output\n",
    "bottom_categories = (                                #Creating a dataset for the bottom ratings by category\n",
    "    final_merged.groupby(\"category\")[\"score\"]\n",
    "    .mean()\n",
    "    .sort_values(ascending=True)   #Bottom / Least\n",
    "    .head(40)      #Shows bottom 40 - initially showed bottom 10 but all were 0\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.barplot(data=bottom_categories, x=\"score\", y=\"category\", hue = \"category\")  #hue - each category will get a unique colour\n",
    "plt.title(\"Bottom Categories by Rating\", fontsize=14, weight=\"bold\")\n",
    "plt.xlabel(\"Rating\")\n",
    "plt.ylabel(\"Product Category\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "39 categories have an average rating of 0 so it isn't really practical to plot the bottom categories - could mention some of the bottom categories instead in report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "reviews_by_state = (\n",
    "    final_merged.groupby(\"state\")[\"total_number_reviews\"].count()   #Dataset to show how many reviews each state gave - only top 20\n",
    "    .sort_values(ascending=False)\n",
    "    .head(20)\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(4, 4))\n",
    "sns.barplot(data=reviews_by_state, x=\"total_number_reviews\", y=\"state\", hue=\"total_number_reviews\")\n",
    "plt.title(\"Top 20 States by Number of Reviews\", fontsize=10, weight=\"bold\")\n",
    "plt.xlabel(\"Number of Reviews\")\n",
    "plt.ylabel(\"State\")\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5), title='Reviews') #Moves the legend to outside the graph so it doesn't overlap\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "reviews_by_statetwo = (\n",
    "    final_merged.groupby(\"state\")[\"total_number_reviews\"].count()  #Dataset to show how many reviews each state gave - only bottom 20\n",
    "    .sort_values(ascending=True)\n",
    "    .head(20)\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(4, 4))\n",
    "sns.barplot(data=reviews_by_statetwo, x=\"total_number_reviews\", y=\"state\", hue=\"total_number_reviews\")\n",
    "plt.title(\"Bottom 20 States by Number of Reviews\", fontsize=10, weight=\"bold\")\n",
    "plt.xlabel(\"Number of Reviews\")\n",
    "plt.ylabel(\"State\")\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5), title='Reviews')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "plt.figure(figsize=(4, 4))\n",
    "sns.regplot(\n",
    "    data=final_merged,\n",
    "    x=\"price\",\n",
    "    y=\"score\",\n",
    "    scatter_kws={\"alpha\": 0.5, \"s\": 30},   #Line to show any correlation between price and average rating\n",
    "    line_kws={\"color\": \"red\"}        \n",
    ")\n",
    "\n",
    "plt.title(\"Relationship Between Price and Customer Average Rating\", fontsize=10, weight=\"bold\")\n",
    "plt.xlabel(\"Product Price ($)\")\n",
    "plt.ylabel(\"Customer Rating (0–5)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "most_reviewed = (\n",
    "    final_merged.groupby(\"name\")[\"total_number_reviews\"]\n",
    "    .count()\n",
    "    .sort_values(ascending=False)     #Dataset to show total number of reviews for each product - top 20 only\n",
    "    .head(20)\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(4, 4))\n",
    "sns.barplot(data=most_reviewed, x=\"total_number_reviews\", y=\"name\", hue= \"name\")\n",
    "plt.title(\"Top 20 Most-Reviewed Products\", fontsize=10, weight=\"bold\")\n",
    "plt.xlabel(\"Number of Reviews\")\n",
    "plt.ylabel(\"Product Name\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "sns.scatterplot(data=final_merged, x='price', y='total_number_reviews')\n",
    "plt.title(\"Relationship Between Product Price and Number of Reviews\")\n",
    "plt.xlabel(\"Product Price ($)\")\n",
    "plt.ylabel(\"Number of Reviews\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(1.4876481581035763)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_avg_rating = final_merged['score'].mean()  #Taking the average score of all \n",
    "overall_avg_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(1.9)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_reviewed = final_merged.nlargest(20, 'total_number_reviews')   #Taking the top 20 most reviewed\n",
    "top_avg_rating = top_reviewed['score'].mean()    #Taking the average score of the top 20 most reviewed\n",
    "top_avg_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "plt.bar(['All Products', 'Top 20 Most-Reviewed'], [overall_avg_rating, top_avg_rating], \n",
    "        color=['pink', 'orange'])\n",
    "plt.title('Average Rating Comparison')\n",
    "plt.ylabel('Average Rating')\n",
    "plt.ylim(0, 5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1963"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_merged[final_merged[\"total_number_reviews\"] == 1].shape[0]   #To see how many items only have 1 review - none had zero"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1963 items only had 1 review, so least reviewed graph - bars just looked identical - not really useful\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Upon doing several plots, I have noticed different outcomes when I use av_score or the mean from score when it should be the same. So that could indicate that the pre-determined average score in the datasets were calculated wrong. When plotting the distribution of the av_score and the scatterplot(few cells below), the plot looked almost perfectly symmetrical and the distribution appeared Guassian(normal distribution). Using the mean of the score appears much more accurate so I intend on using that in each plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                                                name     score  review\n",
       " 0             1 CT. Certified Diamond Solitaire Ring  2.333333       3\n",
       " 1  1 CT. T.W. Certified Diamond 14K White Gold Br...  5.000000       1,\n",
       " (6001, 3))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_rated = (\n",
    "    final_merged.groupby(\"name\", as_index=False)    #Using name of item as first column\n",
    "    [\"score\"].mean()                              #Taking the mean of the scores of each item\n",
    ")\n",
    "\n",
    "most_reviewed = (\n",
    "    final_merged.groupby(\"name\", as_index=False) \n",
    "    [\"review\"].count()            #Counting number of reviews of each item\n",
    ")\n",
    "\n",
    "true_avg = pd.merge(top_rated, most_reviewed, on=\"name\", how=\"inner\")  #merging the average scores with number of reviews \n",
    "true_avg.head(2), true_avg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(71, 479)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_avg[true_avg[\"score\"] == 5].shape[0], true_avg[true_avg[\"score\"] == 0].shape[0] #Checking how many items had an avg score of 5 and 0."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "I will use the true_avg dataset to compare average ratings/review count as it is more accurate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "plt.figure(figsize=(4,4))\n",
    "sns.scatterplot(data=true_avg, x=\"score\", y=\"review\", color=\"lightblue\") #plots a scatterplot for avg score vs total review count \n",
    "plt.title(\"Product Comparison: Average Score vs Review Count\", fontsize=10, weight=\"bold\")\n",
    "plt.xlabel(\"Average Score\")\n",
    "plt.ylabel(\"Number of Reviews\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "#Plotting the distribution of average product scores to visualize how product ratings are spread across all items\n",
    "#This shows general happiness of customers among all products\n",
    "plt.figure(figsize=(4,4))   \n",
    "sns.histplot(data=true_avg, x=\"score\", bins=20, kde=True, color=\"red\")\n",
    "plt.title(\"Distribution of Average Product Scores\", fontsize=10, weight=\"bold\", pad=10)\n",
    "plt.xlabel(\"Average Score\")\n",
    "plt.ylabel(\"Number of Products\")\n",
    "plt.xlim(0, 5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "#This was found on https://gist.github.com/JeffPaine/3083347,  to quickly copy/paste and add a state column to the dataset\n",
    "state_dict = {\n",
    "    \"AK\": \"Alaska\", \"AL\": \"Alabama\", \"AR\": \"Arkansas\", \"AZ\": \"Arizona\", \"CA\": \"California\",\n",
    "    \"CO\": \"Colorado\", \"CT\": \"Connecticut\", \"DE\": \"Delaware\", \"FL\": \"Florida\", \"GA\": \"Georgia\",\n",
    "    \"HI\": \"Hawaii\", \"ID\": \"Idaho\", \"IL\": \"Illinois\", \"IN\": \"Indiana\", \"IA\": \"Iowa\",\n",
    "    \"KS\": \"Kansas\", \"KY\": \"Kentucky\", \"LA\": \"Louisiana\", \"ME\": \"Maine\", \"MD\": \"Maryland\",\n",
    "    \"MA\": \"Massachusetts\", \"MI\": \"Michigan\", \"MN\": \"Minnesota\", \"MS\": \"Mississippi\", \"MO\": \"Missouri\",\n",
    "    \"MT\": \"Montana\", \"NE\": \"Nebraska\", \"NV\": \"Nevada\", \"NH\": \"New Hampshire\", \"NJ\": \"New Jersey\",\n",
    "    \"NM\": \"New Mexico\", \"NY\": \"New York\", \"NC\": \"North Carolina\", \"ND\": \"North Dakota\",\n",
    "    \"OH\": \"Ohio\", \"OK\": \"Oklahoma\", \"OR\": \"Oregon\", \"PA\": \"Pennsylvania\", \"RI\": \"Rhode Island\",\n",
    "    \"SC\": \"South Carolina\", \"SD\": \"South Dakota\", \"TN\": \"Tennessee\", \"TX\": \"Texas\", \"UT\": \"Utah\",\n",
    "    \"VT\": \"Vermont\", \"VA\": \"Virginia\", \"WA\": \"Washington\", \"WV\": \"West Virginia\", \"WI\": \"Wisconsin\",\n",
    "    \"WY\": \"Wyoming\", \"DC\": \"District of Columbia\", \"AS\": \"American Samoa\", \"GU\": \"Guam GU\",\n",
    "    \"MP\": \"Northern Mariana Islands\", \"PR\": \"Puerto Rico PR\", \"VI\": \"U.S. Virgin Islands\"\n",
    "}\n",
    "# Reverse the dictionary \n",
    "state_to_code = {v: k for k, v in state_dict.items()}\n",
    "# Map the column to the dataset\n",
    "final_merged[\"state_code\"] = final_merged[\"state\"].map(state_to_code)\n",
    "final_merged[[\"state\", \"state_code\"]].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Noticed a NaN in the state code so converting all missing values to unknown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "final_merged[\"state_code\"] = final_merged[\"state_code\"].fillna(\"Unknown\")\n",
    "#Fill any missing state codes with 'Unknown' so they can still be tracked if needed\n",
    "final_merged[[\"state\", \"state_code\"]].head(7)\n",
    "#Quick check of the first 7 rows to make sure state codes are filled correctly - as NaN was spotted in the 7th row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import plotly.graph_objects as go #Import Plotly for interactive map visualisation\n",
    "\n",
    "state_summary = (\n",
    "    final_merged.groupby(\"state_code\")[\"score\"]   #Group the data by each U.S. state and calculate the average review score\n",
    "    .mean()\n",
    "    .reset_index(name=\"avg_score\")\n",
    ")\n",
    "\n",
    "fig = go.Figure(\n",
    "    data=go.Choropleth(    #Create a colour-based map showing the average rating per state\n",
    "        locations=state_summary[\"state_code\"],   # State codes\n",
    "        z=state_summary[\"avg_score\"],            # Values to show\n",
    "        locationmode=\"USA-states\",               # Using U.S. state codes\n",
    "        colorscale=\"RdYlGn\",                     #Red,Yellow,Green colour scale\n",
    "        colorbar_title=\"Average Rating\"          #Label for the colour bar\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.update_layout(  #Adding map title and limiting the display area to the USA only\n",
    "    title_text=\"Average Rating by State (JCPenney Dataset)\",\n",
    "    geo_scope=\"usa\"\n",
    ")\n",
    "\n",
    "fig.show()  #Displays the map"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
