{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# University of Stirling\n",
    "\n",
    "# ITNPBD2 Representing and Manipulating Data\n",
    "\n",
    "# Assignment Autumn 2025\n",
    "\n",
    "# A Consultancy Job for JC Penney\n",
    "\n",
    "This notebook forms the assignment instructions and submission document of the assignment for ITNPBD2. Read the instructions carefully and enter code into the cells as indicated.\n",
    "\n",
    "You will need these five files, which were in the Zip file you downloaded from the course webpage:\n",
    "\n",
    "- jcpenney_reviewers.json\n",
    "- jcpenney_products.json\n",
    "- products.csv\n",
    "- reviews.csv\n",
    "- users.csv\n",
    "\n",
    "The data in these files describes products that have been sold by the American retail giant, JC Penney, and reviews by customers who bought them. Note that the product data is real, but the customer data is synthetic.\n",
    "\n",
    "Your job is to process the data, as requested in the instructions in the markdown cells in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Completing the Assignment\n",
    "\n",
    "Rename this file to be xxxxxx_BD2 where xxxxxx is your student number, then type your code and narrative description into the boxes provided. Add as many code and markdown cells as you need. The cells should contain:\n",
    "\n",
    "- **Text narrative describing what you did with the data**\n",
    "- **The code that performs the task you have described**\n",
    "- **Comments that explain your code**\n",
    "\n",
    "The final structure (in PDF) of your report must:\n",
    "- **Start from the main insights observed (max 5 pages)**\n",
    "- **Include as an appendix the source code used for producing those insights (max 15 pages)**\n",
    "- **Include an AI cover sheet (provided on Canvas), which must contain a link to a versioned notebook file in OneDrive or another platform for version checks.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Marking Scheme\n",
    "The assessment will be marked against the university Common Marking Scheme (CMS)\n",
    "\n",
    "Here is a summary of what you need to achieve to gain a grade in the major grade bands:\n",
    "\n",
    "|Grade|Requirement|\n",
    "|:---|:---|\n",
    "| Fail | You will fail if your code does not run or does not achieve even the basics of the task. You may also fail if you submit code without either comments or a text explanation of what the code does.|\n",
    "| Pass | To pass, you must submit sufficient working code to show that you have mastered the basics of the task, even if not everything works completely. You must include some justifications for your choice of methods, but without mentioning alternatives. |\n",
    "| Merit | For a merit, your code must be mostly correct, with only small problems or parts missing, and your comments must be useful rather than simply re-stating the code in English. Most choices for methods and structures should be explained and alternatives mentioned. |\n",
    "| Distinction | For a distinction, your code must be working, correct, and well commented and shows an appreciation of style, efficiency and reliability. All choices for methods and structures are concisely justified and alternatives are given well thought considerations. For a distinction, your work should be good enough to present to executives at the company.|\n",
    "\n",
    "The full details of the CMS can be found here\n",
    "\n",
    "https://www.stir.ac.uk/about/professional-services/student-academic-and-corporate-services/academic-registry/academic-policy-and-practice/quality-handbook/assessment-policy-and-procedure/appendix-2-postgraduate-common-marking-scheme/\n",
    "\n",
    "Note that this means there are not certain numbers of marks allocated to each stage of the assignment. Your grade will reflect how well your solutions and comments demonstrate that you have achieved the learning outcomes of the task. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission\n",
    "When you are ready to submit, **print** your notebook as PDF (go to File -> Print Preview) in the Jupyter menu. Make sure you have run all the cells and that their output is displayed. Any lines of code or comments that are not visible in the pdf should be broken across several lines. You can then submit the file online.\n",
    "\n",
    "Late penalties will apply at a rate of three marks per day, up to a maximum of 7 days. After 7 days you will be given a mark of 0. Extensions will be considered under acceptable circumstances outside your control.\n",
    "\n",
    "## Academic Integrity\n",
    "\n",
    "This is an individual assignment, and so all submitted work must be fully your own work.\n",
    "\n",
    "The University of Stirling is committed to protecting the quality and standards of its awards. Consequently, the University seeks to promote and nurture academic integrity, support staff academic integrity, and support students to understand and develop good academic skills that facilitate academic integrity.\n",
    "\n",
    "In addition, the University deals decisively with all forms of Academic Misconduct.\n",
    "\n",
    "Where a student does not act with academic integrity, their work or behaviour may demonstrate Poor Academic Practice or it may represent Academic Misconduct.\n",
    "\n",
    "### Poor Academic Practice\n",
    "\n",
    "Poor Academic Practice is defined as: \"The submission of any type of assessment with a lack of referencing or inadequate referencing which does not effectively acknowledge the origin of words, ideas, images, tables, diagrams, maps, code, sound and any other sources used in the assessment.\"\n",
    "\n",
    "### Academic Misconduct\n",
    "\n",
    "Academic Misconduct is defined as: \"any act or attempted act that does not demonstrate academic integrity and that may result in creating an unfair academic advantage for you or another person, or an academic disadvantage for any other member or member of the academic community.\"\n",
    "\n",
    "Plagiarism is presenting somebody elseâ€™s work as your own **and includes the use of artificial intelligence tools beyond AIAS Level 2 or the use of Large Language Models.**. Plagiarism is a form of academic misconduct and is taken very seriously by the University. Students found to have plagiarised work can have marks deducted and, in serious cases, even be expelled from the University. Do not submit any work that is not entirely your own. Do not collaborate with or get help from anybody else with this assignment.\n",
    "\n",
    "The University of Stirling's full policy on Academic Integrity can be found at:\n",
    "\n",
    "https://www.stir.ac.uk/about/professional-services/student-academic-and-corporate-services/academic-registry/academic-policy-and-practice/quality-handbook/academic-integrity-policy-and-academic-misconduct-procedure/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Assignment\n",
    "Your task with this assignment is to use the data provided to demonstrate your Python data manipulation skills.\n",
    "\n",
    "There are three `.csv` files and two `.json` files so you can process different types of data. The files also contain unstructured data in the form of natural language in English and links to images that you can access from the JC Penney website (use the field called `product_image_urls`).\n",
    "\n",
    "Start with easy tasks to show you can read in a file, create some variables and data structures, and manipulate their contents. Then move onto something more interesting.\n",
    "\n",
    "Look at the data that we provided with this assessment and think of something interesting to do with it using whatever libraries you like. Describe what you decide to do with the data and why it might be interesting or useful to the company to do it.\n",
    "\n",
    "You can add additional data if you need to - either download it or access it using `requests`. Produce working code to implement your ideas in as many cells as you need below. There is no single right answer, the aim is to simply show you are competent in using python for data analysis. Exactly how you do that is up to you.\n",
    "\n",
    "For a distinction class grade, this must show originality, creative thinking, and insights beyond what you've been taught directly on the module."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structure\n",
    "You may structure the appendix of the project how you wish, but here is a suggested guideline to help you organise your work, based on the CRISP-DM data science methodology:\n",
    "\n",
    " 1. **Business understanding** - What business context is the data coming from? What insights would be valuable in that context, and what data would be required for that purporse? \n",
    " 2. **Data understanding and preparation** - Explore the data and show you understand its structure and relations, with the aid of appropriate visualisation techniques. Assess the data quality, which insights you would be able to answer from it, and what preparation the data would require. Add new data from another source if required to bring new insights to the data you already have.\n",
    " 3. **Data modeling (optional)** - Would modeling be required for the insights you have considered? Use appropriate techniques, if so.\n",
    " 4. **Evaluation and deployment** - How do the insights you obtained help the company, and how can should they be adopted in their business? If modeling techniques have been adopted, are their use scientifically sound and how should they be mantained?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remember to make sure you are working completely on your own.\n",
    "# Don't work in a group or with a friend\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "briefly describe the data sets - purpose of the analysis\n",
    "\n",
    "## Data Preparation\n",
    "explain how I cleaned the data, the reasoning behind what i did, can include a short summary of the finalised data\n",
    "\n",
    "## Analysis/Insights/Visualisation\n",
    "What did i find out about the data set - include the graphs - how do these insights help the company - how can these insights be adopted into the business? - ideas- no of reviews by states: which states gives the most reviews? - highest rated products? - relationship between rating and price? - highest rated brands? - most reviewed products? - price vs rating, any correlation? \n",
    "\n",
    "## Conclusion\n",
    "Summarise everything here and what it means for JC Penny\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  #Importing necessary libraries\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "def load_json_lines(filepath):\n",
    "    data = [] #creates an empty list to store the JSON objects\n",
    "    with open(filepath, \"r\") as f:  #Opens the file for reading\n",
    "        for line in f:\n",
    "            try:\n",
    "                data.append(json.loads(line))   #Adds each JSON object to the list\n",
    "            except json.JSONDecodeError:\n",
    "                continue                #Will skip any lines not valid\n",
    "    return pd.json_normalize(data)   #Converts the list into a Pandas dataframe\n",
    "\n",
    "#Loading all the files\n",
    "products = pd.read_csv(\"products[1].csv\")\n",
    "reviews = pd.read_csv(\"reviews[1].csv\")\n",
    "users = pd.read_csv(\"users[1].csv\")\n",
    "jc_products = load_json_lines(\"jcpenney_products[1].json\")\n",
    "jc_reviewers = load_json_lines(\"jcpenney_reviewers[1].json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7982 entries, 0 to 7981\n",
      "Data columns (total 6 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   Uniq_id      7982 non-null   object \n",
      " 1   SKU          7915 non-null   object \n",
      " 2   Name         7982 non-null   object \n",
      " 3   Description  7439 non-null   object \n",
      " 4   Price        5816 non-null   float64\n",
      " 5   Av_Score     7982 non-null   float64\n",
      "dtypes: float64(2), object(4)\n",
      "memory usage: 374.3+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(                            Uniq_id           SKU  \\\n",
       " 0  b6c0b6bea69c722939585baeac73c13d  pp5006380337   \n",
       " 1  93e5272c51d8cce02597e3ce67b7ad0a  pp5006380337   \n",
       " 2  013e320f2f2ec0cf5b3ff5418d688528  pp5006380337   \n",
       " 3  505e6633d81f2cb7400c0cfa0394c427  pp5006380337   \n",
       " 4  d969a8542122e1331e304b09f81a83f6  pp5006380337   \n",
       " \n",
       "                                           Name  \\\n",
       " 0  Alfred DunnerÂ® Essential Pull On Capri Pant   \n",
       " 1  Alfred DunnerÂ® Essential Pull On Capri Pant   \n",
       " 2  Alfred DunnerÂ® Essential Pull On Capri Pant   \n",
       " 3  Alfred DunnerÂ® Essential Pull On Capri Pant   \n",
       " 4  Alfred DunnerÂ® Essential Pull On Capri Pant   \n",
       " \n",
       "                                          Description  Price  Av_Score  \n",
       " 0  Youll return to our Alfred Dunner pull-on capr...  41.09     2.625  \n",
       " 1  Youll return to our Alfred Dunner pull-on capr...  41.09     3.000  \n",
       " 2  Youll return to our Alfred Dunner pull-on capr...  41.09     2.625  \n",
       " 3  Youll return to our Alfred Dunner pull-on capr...  41.09     3.500  \n",
       " 4  Youll return to our Alfred Dunner pull-on capr...  41.09     3.125  ,\n",
       " None)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products.head(), products.info()  #To see an overview of the dataframe, column names/data types/non-null counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['uniq_id', 'sku', 'name', 'description', 'price', 'av_score'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "products.columns = (    #Begin to clean the column names\n",
    "    products.columns\n",
    "    .str.lower()       #Put it all into lower case\n",
    "    .str.strip()       #Remove spaces\n",
    "    .str.replace(\" \", \"_\")  #To use underscores instead\n",
    ")\n",
    "\n",
    "print(products.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "uniq_id           0\n",
       "sku              67\n",
       "name              0\n",
       "description     543\n",
       "price          2166\n",
       "av_score          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products.isna().sum() #To see if there is any missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Id/name/score all have 7982 non-null count, so I aim to make description/price/sku the same\n",
    "products[\"description\"] = products[\"description\"].fillna(\"No description available\") #Replacing empty values in description column with \"No description available\"\n",
    "\n",
    "products[\"price\"] = products[\"price\"].fillna(products[\"price\"].median())  #Fills any missing prices with a median price to help balance the dataset instead of completely removing those rows\n",
    "\n",
    "    #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "uniq_id         0\n",
       "sku            67\n",
       "name            0\n",
       "description     0\n",
       "price           0\n",
       "av_score        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products.isna().sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "uniq_id        0\n",
       "sku            0\n",
       "name           0\n",
       "description    0\n",
       "price          0\n",
       "av_score       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products[\"sku\"] = products[\"sku\"].fillna(\"unknown\") # Replace missing SKU values with \"unknown\" to keep the row but mark it clearly.\n",
    "products.isna().sum() \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7982 entries, 0 to 7981\n",
      "Data columns (total 6 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   uniq_id      7982 non-null   object \n",
      " 1   sku          7982 non-null   object \n",
      " 2   name         7982 non-null   object \n",
      " 3   description  7982 non-null   object \n",
      " 4   price        7982 non-null   float64\n",
      " 5   av_score     7982 non-null   float64\n",
      "dtypes: float64(2), object(4)\n",
      "memory usage: 374.3+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(                            uniq_id           sku  \\\n",
       " 0  b6c0b6bea69c722939585baeac73c13d  pp5006380337   \n",
       " 1  93e5272c51d8cce02597e3ce67b7ad0a  pp5006380337   \n",
       " 2  013e320f2f2ec0cf5b3ff5418d688528  pp5006380337   \n",
       " 3  505e6633d81f2cb7400c0cfa0394c427  pp5006380337   \n",
       " 4  d969a8542122e1331e304b09f81a83f6  pp5006380337   \n",
       " \n",
       "                                           name  \\\n",
       " 0  Alfred DunnerÂ® Essential Pull On Capri Pant   \n",
       " 1  Alfred DunnerÂ® Essential Pull On Capri Pant   \n",
       " 2  Alfred DunnerÂ® Essential Pull On Capri Pant   \n",
       " 3  Alfred DunnerÂ® Essential Pull On Capri Pant   \n",
       " 4  Alfred DunnerÂ® Essential Pull On Capri Pant   \n",
       " \n",
       "                                          description  price  av_score  \n",
       " 0  Youll return to our Alfred Dunner pull-on capr...  41.09     2.625  \n",
       " 1  Youll return to our Alfred Dunner pull-on capr...  41.09     3.000  \n",
       " 2  Youll return to our Alfred Dunner pull-on capr...  41.09     2.625  \n",
       " 3  Youll return to our Alfred Dunner pull-on capr...  41.09     3.500  \n",
       " 4  Youll return to our Alfred Dunner pull-on capr...  41.09     3.125  ,\n",
       " None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products.head(), products.info() #Review the dataset again to see if the changes have been made"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 39063 entries, 0 to 39062\n",
      "Data columns (total 4 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   Uniq_id   39063 non-null  object\n",
      " 1   Username  39063 non-null  object\n",
      " 2   Score     39063 non-null  int64 \n",
      " 3   Review    39063 non-null  object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 1.2+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(                            Uniq_id  Username  Score  \\\n",
       " 0  b6c0b6bea69c722939585baeac73c13d  fsdv4141      2   \n",
       " 1  b6c0b6bea69c722939585baeac73c13d  krpz1113      1   \n",
       " 2  b6c0b6bea69c722939585baeac73c13d  mbmg3241      2   \n",
       " 3  b6c0b6bea69c722939585baeac73c13d  zeqg1222      0   \n",
       " 4  b6c0b6bea69c722939585baeac73c13d  nvfn3212      3   \n",
       " \n",
       "                                               Review  \n",
       " 0  You never have to worry about the fit...Alfred...  \n",
       " 1  Good quality fabric. Perfect fit. Washed very ...  \n",
       " 2  I do not normally wear pants or capris that ha...  \n",
       " 3  I love these capris! They fit true to size and...  \n",
       " 4  This product is very comfortable and the fabri...  ,\n",
       " None)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.head(), reviews.info() #Now looking at the reviews file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews.columns = (  #To keep column names consistant with every data set, I will be making them all lower case, removing spaces and adding \"_\" instead\n",
    "    reviews.columns\n",
    "    .str.lower()\n",
    "    .str.strip()\n",
    "    .str.replace(\" \", \"_\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7982, 7982)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products[\"uniq_id\"].nunique(), reviews[\"uniq_id\"].nunique()  #I wanted to make sure there is a unique number of IDs in both files to make sure they match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   Username  5000 non-null   object\n",
      " 1   DOB       5000 non-null   object\n",
      " 2   State     5000 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 117.3+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(   Username         DOB          State\n",
       " 0  bkpn1412  31.07.1983         Oregon\n",
       " 1  gqjs4414  27.07.1998  Massachusetts\n",
       " 2  eehe1434  08.08.1950          Idaho\n",
       " 3  hkxj1334  03.08.1969        Florida\n",
       " 4  jjbd1412  26.07.2001        Georgia,\n",
       " None)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users.head(), users.info()  #Looking at users file summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "users.columns = (  #Keeping consistancy in column names\n",
    "    users.columns\n",
    "    .str.lower()\n",
    "    .str.strip()\n",
    "    .str.replace(\" \", \"_\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   username  5000 non-null   object\n",
      " 1   dob       5000 non-null   object\n",
      " 2   state     5000 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 117.3+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(   username         dob          state\n",
       " 0  bkpn1412  31.07.1983         Oregon\n",
       " 1  gqjs4414  27.07.1998  Massachusetts\n",
       " 2  eehe1434  08.08.1950          Idaho\n",
       " 3  hkxj1334  03.08.1969        Florida\n",
       " 4  jjbd1412  26.07.2001        Georgia,\n",
       " None)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users.head(), users.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   1983-07-31\n",
       "1   1998-07-27\n",
       "2   1950-08-08\n",
       "3   1969-08-03\n",
       "4   2001-07-26\n",
       "Name: dob, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users[\"dob\"] = pd.to_datetime(users[\"dob\"], format=\"%d.%m.%Y\", errors=\"coerce\")  #Converts the date of birth from strings to datetime objects for easier analysis\n",
    "\n",
    "users[\"dob\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['Oregon', 'Massachusetts', 'Idaho', 'Florida', 'Georgia',\n",
       "        'Montana', 'Pennsylvania', 'Connecticut', 'Arkansas', 'Nebraska',\n",
       "        'California', 'New Hampshire', 'District of Columbia',\n",
       "        'Washington', 'Minnesota', 'New Mexico', 'Virginia', 'Kansas',\n",
       "        'Illinois', 'North Dakota', 'Colorado', 'New York',\n",
       "        'Minor Outlying Islands', 'Northern Mariana Islands',\n",
       "        'West Virginia', 'Texas', 'South Dakota', 'Maryland', 'Maine',\n",
       "        'Ohio', 'Rhode Island', 'Michigan', 'Alaska', 'Iowa', 'Oklahoma',\n",
       "        'Mississippi', 'South Carolina', 'Missouri', 'New Jersey',\n",
       "        'Tennessee', 'North Carolina', 'Guam', 'Wyoming', 'Delaware',\n",
       "        'Vermont', 'Indiana', 'Louisiana', 'Wisconsin', 'Hawaii',\n",
       "        'Puerto Rico', 'Alabama', 'Kentucky', 'Arizona', 'Nevada', 'Utah',\n",
       "        'American Samoa', 'U.S. Virgin Islands'], dtype=object),\n",
       " 57)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users[\"state\"].unique(), users[\"state\"].nunique()  #Making sure there is no duplicate states just incase some may have been repeated by beginning in lower case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7982 entries, 0 to 7981\n",
      "Data columns (total 15 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   uniq_id                 7982 non-null   object \n",
      " 1   sku                     7982 non-null   object \n",
      " 2   name_title              7982 non-null   object \n",
      " 3   description             7982 non-null   object \n",
      " 4   list_price              7982 non-null   object \n",
      " 5   sale_price              7982 non-null   object \n",
      " 6   category                7982 non-null   object \n",
      " 7   category_tree           7982 non-null   object \n",
      " 8   average_product_rating  7982 non-null   float64\n",
      " 9   product_url             7982 non-null   object \n",
      " 10  product_image_urls      7982 non-null   object \n",
      " 11  brand                   7982 non-null   object \n",
      " 12  total_number_reviews    7982 non-null   int64  \n",
      " 13  Reviews                 7982 non-null   object \n",
      " 14  Bought With             7982 non-null   object \n",
      "dtypes: float64(1), int64(1), object(13)\n",
      "memory usage: 935.5+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(                            uniq_id           sku  \\\n",
       " 0  b6c0b6bea69c722939585baeac73c13d  pp5006380337   \n",
       " 1  93e5272c51d8cce02597e3ce67b7ad0a  pp5006380337   \n",
       " 2  013e320f2f2ec0cf5b3ff5418d688528  pp5006380337   \n",
       " 3  505e6633d81f2cb7400c0cfa0394c427  pp5006380337   \n",
       " 4  d969a8542122e1331e304b09f81a83f6  pp5006380337   \n",
       " \n",
       "                                     name_title  \\\n",
       " 0  Alfred DunnerÂ® Essential Pull On Capri Pant   \n",
       " 1  Alfred DunnerÂ® Essential Pull On Capri Pant   \n",
       " 2  Alfred DunnerÂ® Essential Pull On Capri Pant   \n",
       " 3  Alfred DunnerÂ® Essential Pull On Capri Pant   \n",
       " 4  Alfred DunnerÂ® Essential Pull On Capri Pant   \n",
       " \n",
       "                                          description list_price sale_price  \\\n",
       " 0  You'll return to our Alfred Dunner pull-on cap...      41.09      24.16   \n",
       " 1  You'll return to our Alfred Dunner pull-on cap...      41.09      24.16   \n",
       " 2  You'll return to our Alfred Dunner pull-on cap...      41.09      24.16   \n",
       " 3  You'll return to our Alfred Dunner pull-on cap...      41.09      24.16   \n",
       " 4  You'll return to our Alfred Dunner pull-on cap...      41.09      24.16   \n",
       " \n",
       "         category                 category_tree  average_product_rating  \\\n",
       " 0  alfred dunner  jcpenney|women|alfred dunner                   2.625   \n",
       " 1  alfred dunner  jcpenney|women|alfred dunner                   3.000   \n",
       " 2       view all       jcpenney|women|view all                   2.625   \n",
       " 3       view all       jcpenney|women|view all                   3.500   \n",
       " 4       view all       jcpenney|women|view all                   3.125   \n",
       " \n",
       "                                          product_url  \\\n",
       " 0  http://www.jcpenney.com/alfred-dunner-essentia...   \n",
       " 1  http://www.jcpenney.com/alfred-dunner-essentia...   \n",
       " 2  http://www.jcpenney.com/alfred-dunner-essentia...   \n",
       " 3  http://www.jcpenney.com/alfred-dunner-essentia...   \n",
       " 4  http://www.jcpenney.com/alfred-dunner-essentia...   \n",
       " \n",
       "                                   product_image_urls          brand  \\\n",
       " 0  http://s7d9.scene7.com/is/image/JCPenney/DP122...  Alfred Dunner   \n",
       " 1  http://s7d9.scene7.com/is/image/JCPenney/DP122...  Alfred Dunner   \n",
       " 2  http://s7d9.scene7.com/is/image/JCPenney/DP122...  Alfred Dunner   \n",
       " 3  http://s7d9.scene7.com/is/image/JCPenney/DP122...  Alfred Dunner   \n",
       " 4  http://s7d9.scene7.com/is/image/JCPenney/DP122...  Alfred Dunner   \n",
       " \n",
       "    total_number_reviews                                            Reviews  \\\n",
       " 0                     8  [{'User': 'fsdv4141', 'Review': 'You never hav...   \n",
       " 1                     8  [{'User': 'tpcu2211', 'Review': 'You never hav...   \n",
       " 2                     8  [{'User': 'pcfg3234', 'Review': 'You never hav...   \n",
       " 3                     8  [{'User': 'ngrq4411', 'Review': 'You never hav...   \n",
       " 4                     8  [{'User': 'nbmi2334', 'Review': 'You never hav...   \n",
       " \n",
       "                                          Bought With  \n",
       " 0  [898e42fe937a33e8ce5e900ca7a4d924, 8c02c262567...  \n",
       " 1  [bc9ab3406dcaa84a123b9da862e6367d, 18eb69e8fc2...  \n",
       " 2  [3ce70f519a9cfdd85cdbdecd358e5347, b0295c96d2b...  \n",
       " 3  [efcd811edccbeb5e67eaa8ef0d991f7c, 7b2cc00171e...  \n",
       " 4  [0ca5ad2a218f59eb83eec1e248a0782d, 9869fc8da14...  ,\n",
       " None)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jc_products.head(), jc_products.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7982 entries, 0 to 7981\n",
      "Data columns (total 15 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   uniq_id                 7982 non-null   object \n",
      " 1   sku                     7982 non-null   object \n",
      " 2   name_title              7982 non-null   object \n",
      " 3   description             7982 non-null   object \n",
      " 4   list_price              7982 non-null   object \n",
      " 5   sale_price              7982 non-null   object \n",
      " 6   category                7982 non-null   object \n",
      " 7   category_tree           7982 non-null   object \n",
      " 8   average_product_rating  7982 non-null   float64\n",
      " 9   product_url             7982 non-null   object \n",
      " 10  product_image_urls      7982 non-null   object \n",
      " 11  brand                   7982 non-null   object \n",
      " 12  total_number_reviews    7982 non-null   int64  \n",
      " 13  reviews                 7982 non-null   object \n",
      " 14  bought_with             7982 non-null   object \n",
      "dtypes: float64(1), int64(1), object(13)\n",
      "memory usage: 935.5+ KB\n"
     ]
    }
   ],
   "source": [
    "jc_products.columns = (  #Noticed some capital letters again in column names so doing this for consistancy with names\n",
    "    jc_products.columns\n",
    "    .str.lower()\n",
    "    .str.strip()\n",
    "    .str.replace(\" \", \"_\")\n",
    ")\n",
    "\n",
    "jc_products.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "uniq_id                   0\n",
       "sku                       0\n",
       "name_title                0\n",
       "description               0\n",
       "list_price                0\n",
       "sale_price                0\n",
       "category                  0\n",
       "category_tree             0\n",
       "average_product_rating    0\n",
       "product_url               0\n",
       "product_image_urls        0\n",
       "brand                     0\n",
       "total_number_reviews      0\n",
       "reviews                   0\n",
       "bought_with               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jc_products.isna().sum() #Noticed all non-null counts correct but double checking for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 4 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   Username  5000 non-null   object\n",
      " 1   DOB       5000 non-null   object\n",
      " 2   State     5000 non-null   object\n",
      " 3   Reviewed  5000 non-null   object\n",
      "dtypes: object(4)\n",
      "memory usage: 156.4+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(   Username         DOB          State  \\\n",
       " 0  bkpn1412  31.07.1983         Oregon   \n",
       " 1  gqjs4414  27.07.1998  Massachusetts   \n",
       " 2  eehe1434  08.08.1950          Idaho   \n",
       " 3  hkxj1334  03.08.1969        Florida   \n",
       " 4  jjbd1412  26.07.2001        Georgia   \n",
       " \n",
       "                                             Reviewed  \n",
       " 0                 [cea76118f6a9110a893de2b7654319c0]  \n",
       " 1                 [fa04fe6c0dd5189f54fe600838da43d3]  \n",
       " 2                                                 []  \n",
       " 3  [f129b1803f447c2b1ce43508fb822810, 3b0c9bc0be6...  \n",
       " 4                                                 []  ,\n",
       " None)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jc_reviewers.head(),jc_reviewers.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 4 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   username  5000 non-null   object\n",
      " 1   dob       5000 non-null   object\n",
      " 2   state     5000 non-null   object\n",
      " 3   reviewed  5000 non-null   object\n",
      "dtypes: object(4)\n",
      "memory usage: 156.4+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None,\n",
       "    username         dob          state  \\\n",
       " 0  bkpn1412  31.07.1983         Oregon   \n",
       " 1  gqjs4414  27.07.1998  Massachusetts   \n",
       " 2  eehe1434  08.08.1950          Idaho   \n",
       " 3  hkxj1334  03.08.1969        Florida   \n",
       " 4  jjbd1412  26.07.2001        Georgia   \n",
       " \n",
       "                                             reviewed  \n",
       " 0                 [cea76118f6a9110a893de2b7654319c0]  \n",
       " 1                 [fa04fe6c0dd5189f54fe600838da43d3]  \n",
       " 2                                                 []  \n",
       " 3  [f129b1803f447c2b1ce43508fb822810, 3b0c9bc0be6...  \n",
       " 4                                                 []  )"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jc_reviewers.columns = (  #Consistancy\n",
    "    jc_reviewers.columns\n",
    "    .str.lower()\n",
    "    .str.strip()\n",
    "    .str.replace(\" \", \"_\")\n",
    ")\n",
    "\n",
    "jc_reviewers.info(), jc_reviewers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>dob</th>\n",
       "      <th>state</th>\n",
       "      <th>reviewed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bkpn1412</td>\n",
       "      <td>1983-07-31</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>[cea76118f6a9110a893de2b7654319c0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gqjs4414</td>\n",
       "      <td>1998-07-27</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>[fa04fe6c0dd5189f54fe600838da43d3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eehe1434</td>\n",
       "      <td>1950-08-08</td>\n",
       "      <td>Idaho</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hkxj1334</td>\n",
       "      <td>1969-08-03</td>\n",
       "      <td>Florida</td>\n",
       "      <td>[f129b1803f447c2b1ce43508fb822810, 3b0c9bc0be6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jjbd1412</td>\n",
       "      <td>2001-07-26</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   username        dob          state  \\\n",
       "0  bkpn1412 1983-07-31         Oregon   \n",
       "1  gqjs4414 1998-07-27  Massachusetts   \n",
       "2  eehe1434 1950-08-08          Idaho   \n",
       "3  hkxj1334 1969-08-03        Florida   \n",
       "4  jjbd1412 2001-07-26        Georgia   \n",
       "\n",
       "                                            reviewed  \n",
       "0                 [cea76118f6a9110a893de2b7654319c0]  \n",
       "1                 [fa04fe6c0dd5189f54fe600838da43d3]  \n",
       "2                                                 []  \n",
       "3  [f129b1803f447c2b1ce43508fb822810, 3b0c9bc0be6...  \n",
       "4                                                 []  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jc_reviewers[\"dob\"] = pd.to_datetime(jc_reviewers[\"dob\"], format=\"%d.%m.%Y\", errors=\"coerce\")  #Converting to datetime objects again \n",
    "\n",
    "jc_reviewers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "username    0\n",
       "dob         0\n",
       "state       0\n",
       "reviewed    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jc_reviewers.isna().sum() #Checking for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['Oregon', 'Massachusetts', 'Idaho', 'Florida', 'Georgia',\n",
       "        'Montana', 'Pennsylvania', 'Connecticut', 'Arkansas', 'Nebraska',\n",
       "        'California', 'New Hampshire', 'District of Columbia',\n",
       "        'Washington', 'Minnesota', 'New Mexico', 'Virginia', 'Kansas',\n",
       "        'Illinois', 'North Dakota', 'Colorado', 'New York',\n",
       "        'Minor Outlying Islands', 'Northern Mariana Islands',\n",
       "        'West Virginia', 'Texas', 'South Dakota', 'Maryland', 'Maine',\n",
       "        'Ohio', 'Rhode Island', 'Michigan', 'Alaska', 'Iowa', 'Oklahoma',\n",
       "        'Mississippi', 'South Carolina', 'Missouri', 'New Jersey',\n",
       "        'Tennessee', 'North Carolina', 'Guam', 'Wyoming', 'Delaware',\n",
       "        'Vermont', 'Indiana', 'Louisiana', 'Wisconsin', 'Hawaii',\n",
       "        'Puerto Rico', 'Alabama', 'Kentucky', 'Arizona', 'Nevada', 'Utah',\n",
       "        'American Samoa', 'U.S. Virgin Islands'], dtype=object),\n",
       " 57)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jc_reviewers[\"state\"].unique(), jc_reviewers[\"state\"].nunique()  #Making sure the states match up with the reviews file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
